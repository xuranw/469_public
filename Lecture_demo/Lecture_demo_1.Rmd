---
title: "Lecture_demo_1"
author: "Xuran Wang"
date: "9/15/2021"
output:
  html_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Loading Data
load in some functions that might be useful
```{r}
source("https://raw.githubusercontent.com/xuranw/469_public/master/hw2/hw2_functions.R")
```
load in data, basic exploration
```{r}
dat <- read.csv("https://raw.githubusercontent.com/xuranw/469_public/master/hw2/framingham.csv")
dim(dat)
colnames(dat)
head(dat)
#summary(dat)
#str(dat)
```
for datasets like these (unlike SNP data), it's in your best interest to rescale the data you don't need to do this step in your homework remove education since it's categorical with more than 2 levels

```{r}
dat <- dat[,-which(colnames(dat) == "Educ")]
idx <- which(colnames(dat) == "AnyCHD")
factor_idx <- which(apply(dat, 2, function(x){length(unique(x)) <= 5}))
dat[,-factor_idx] <- as.data.frame(scale(dat[,-factor_idx, drop = F]))
#head(dat)
#summary(dat)
```
in general, outside of this course, this preprocessing/cleaning step is typically the one that will give you the most headache. forunately, for homeworks in this course we'll clean the data for you so you can jump (more-or-less) immediately to the "statistics" part of the analyses outside of this course, you might find the `stats::model.matrix` useful.

# Odds Ratios
Suppose there are two categories, one refer to 
```{r}
## AnyCHD <- Diseased/Control, and CurSmoke <- Exposed/Not Exposed
cursmoke <- (dat$CurSmoke == 1)
tab <- table(cursmoke, dat$AnyCHD)[c(2,1),c(2,1)] # columns represent Diseased/Health, rows represent Exposed/Not Exposed
tab
((tab[1,1]/tab[1,2])/(tab[2,1]/tab[2,2])) # Odds ratio
```
What can we say about this odds ratio? 

```{r}
# BPMeds: anti-hypertensive medication 0: not use/ 1: use
bpmeds <- (dat$BPMeds == 1)
tab <- table(bpmeds, dat$AnyCHD)[c(2,1),c(2,1)] # columns represent Diseased/Health, rows represent Exposed/Not Exposed
tab
((tab[1,1]/tab[1,2])/(tab[2,1]/tab[2,2])) # Odds ratio
```

# Logistic Regression

```{r}
glm_res <- stats::glm(AnyCHD ~ . , data = dat, family = stats::binomial)
```
if you want to omit the intercept, we can use the following
```{r}
#glm_res <- stats::glm(AnyCHD ~ . - 1, data = dat, family = stats::binomial)
```
the "-1" in the formula omits the intercept.
```{r}
class(dat)
glm_res
```
Note: the following line of code will __NOT__ work and this demonstrates that the input dataset into glm MUST be a data frame

```{r}
# glm_res <- stats::glm(AnyCHD ~ ., data = as.matrix(dat), family = stats::binomial)
```
note: the `stats::` prefix I put before `glm` is simply for explicitly. This is R-lingo for telling R which package to specifically grab the `glm` function from. In most cases, you can omit `stats::` (or any package name prefix), and nothing will change. However, I will be doing this (whenever I remember) to explicitly remind students which package I'm using, which will become more useful as we start using functions for many different packages.

## Extract Estimated Coefficients
### Method 1
This is what you would usually do, outside of this homework.
```{r}
coef_vec1 <- stats::coef(glm_res)
coef_vec1
length(coef_vec1) == (ncol(dat)-1)+1
```
### Method 2
For now, use the output_coefficients function provided for this homework.
```{r}
coef_vec2 <- output_coefficients(glm_res, dat, idx)
```
### Method 3
As it turns out, the `glm_res` obj contains the coefficients inside it, so we can just navigate and extract it directly.
```{r}
coef_vec3 <- glm_res$coefficients
```
check to see we got the same thing
```{r}
length(coef_vec1) == length(coef_vec2)
sum(abs(coef_vec1 - coef_vec2)) <= 1e-6
```

summarize the fit (and see which ones are significant)
```{r}
summary(glm_res)
```

## Form predictions
### Method 1
what you would usually do, outside of this homework read the documentation for stats::predict.glm for more information
```{r}
pred_vec1 <-  stats::predict(glm_res, newx = dat, type = "response")
head(pred_vec1) # these are the probabilities to be in one of the classes
pred_vec1 <- as.numeric(pred_vec1 >= 0.5) # converting it to a 0-1
head(pred_vec1) 
```
note: if you're familiar with ROC curves, you'll realize that this threshold of 0.5 is yet another parameter you can tune. We might revisit this in Chapter 4 later in the course

### Method 2: 
for now, you can use the output_predictions function provided for this homework
```{r}
pred_vec2 <- output_predictions(glm_res, dat, idx)
```
### Method 3: 
if you're really hardcore, you can compute the predictions yourself this is primarily useful only as a learning exercise, to make sure you know what is going behind the scenes with the `stats::predict` function
```{r}
pred_vec3 <- as.numeric(1/(1+exp(-(data.matrix(cbind(1, dat[,-idx]))%*%coef_vec1))))
pred_vec3 <- as.numeric(pred_vec3 >= 0.5) 
```
We can reproduce the S-shape in Chapter 2
```{r}
ghat = data.matrix(cbind(1, dat[, -idx]))%*% data.matrix(coef_vec1)
logit = function(s){  # define logit function
  log(s/(1-s))
}
pred_p_vec = stats::predict(glm_res, newx = dat, type = "response")
par(mfrow = c(1, 2))
plot(pred_p_vec, logit(pred_p_vec))
plot(pred_p_vec, ghat)
#dev.off()
```
check to see we got the same thing:
```{r}
length(pred_vec1) == length(pred_vec2)
sum(abs(pred_vec1 - pred_vec2)) <= 1e-6
length(pred_vec1) == length(pred_vec3)
sum(abs(pred_vec1 - pred_vec3)) <= 1e-6
```

## Misclassification Rate
after extracting predictions, we can compute the misclassification rate
```{r}
obs_response <- dat$AnyCHD
tab <- table(pred_vec1, obs_response) 
tab
```
The different rows reflect different estimated responses and the different columns reflect different observed responses.
to compute the misclassification rate, simply sum the diagonal terms, divided by the grand sum
```{r}
1 - sum(diag(tab))/sum(tab)
```
note: in general, the labeling of the estimated responses is arbitrary, so outside of this homework, you need to try permuting the class labels, and seeing which permutation yields a lower misclassification rate
```{r}
1 - sum(diag(tab[c(2,1),]))/sum(tab) 
```
for this homework, you won't need to worry about this permutation.

## Visualizations
We can make some plots to better visualize the results

### plotting the coefficients
This is beyond the homework, but it's good to see how to make these types of plots. You might be familiar with `ggplot`, but in our class, we typically give our examples in base R, since we don't assume familiarity with `ggplot` or any `tidyverse`-related package
```{r}
coef_vec <- stats::coef(glm_res)

## extract standard errors
name_vec <- names(coef_vec)
names(coef_vec) <- NULL
sum_mat <- summary(glm_res)
sd_vec <- sum_mat$coefficients[,2]

orange <- grDevices::rgb(232, 125, 49, max = 255)
blue <- grDevices::rgb(162, 215, 216, max = 255)
res <- graphics::barplot(coef_vec, col = orange, ylim = range(c(coef_vec - sd_vec,coef_vec + sd_vec)),
                         main = "Coefficients for logisitic model")
graphics::abline(0, 0, lwd = 2)
graphics::text(as.numeric(res), min(coef_vec - sd_vec)-0.05, srt = -45, adj = 0,
               xpd = T, labels = name_vec, cex = 1)
graphics::arrows(res, coef_vec + sd_vec, res, coef_vec - sd_vec, angle=90, code=3, 
                 length=0.1)
```

### plotting the log-odds
We need to jitter the response (the `0.05*stats::rnorm`... part) so we can see the different values. Notice that this is plotting the logit function:
```{r}
pred_vec <- stats::predict(glm_res, type = "response", newdata = dat)
ord <- order(pred_vec)

par(mar = c(4,6,4,0.5))

graphics::plot(pred_vec[ord], 
               col = c(orange, blue)[dat$AnyCHD+1][ord], pch = 16,
               xlab = "Subject index (Ordered)", 
               ylab = "Predicted probability of CHD",
               main = "Predicted probability of subjects for CHD")
graphics::lines(x = c(-1e4,1e4), y = rep(0.5, 2), 
                col = "black", lty = 2, lwd = 3)
legend("topleft", c("Had CHD", "Did not have CHD"), 
       bty="n", fill=c(blue, orange))

graphics::plot(pred_vec[ord] + 0.05*stats::rnorm(1:length(ord)), 
               col = c(orange, blue)[dat$AnyCHD+1][ord], pch = 16,
               xlab = "Subject index (Ordered)", 
               ylab = "Predicted probability of CHD\n(With Jitter)",
               main = "Predicted probability of subjects for CHD")
graphics::lines(x = c(-1e4,1e4), y = rep(0.5, 2), 
                col = "black", lty = 2, lwd = 3)
legend("topleft", c("Had CHD", "Did not have CHD"), 
       bty="n", fill=c(blue, orange))
```

# Lasso Regression
You need to install the glmnet package first, via `install.packages("glmnet")`.
```{r}
library(glmnet)
```
We use the same dataset as in Logistic regression
```{r}
idx <- which(colnames(dat) == "AnyCHD")
head(dat)
```

## Fitting Lasso (no cross-validation)
for kicks, let us try to regress HeartRate onto TotChol, Age, SysBP, DiaBP, CigPDay, BMI and Glucose.
```{r}
response_idx <- which(colnames(dat) == "HeartRate")
covariate_idx <- which(colnames(dat) %in% c("TotChol", "Age", "SysBP", "DiaBP", "CigPDay", "BMI", "Glucose"))
dat2 <- dat[,c(response_idx,covariate_idx)]
```
We do not include an intercept here just for demonstration
```{r}
glmnet_res <- glmnet::glmnet(x = as.matrix(dat2[,-1]), y = dat2[,1], family = "gaussian",
                             intercept = F)
class(glmnet_res)
names(glmnet_res) # a0 contains the intercepts, beta contains the coefficients, lambda contains the tuning parameter
```
By default, the parameter `alpha=1`, meaning glmnet is fitting the lasso be sure to read the documentation for glmnet (i.e., ?glmnet::glmnet)

now that we fitted the lasso, let's take a look at what it is
```{r}
glmnet_res # not very interpretable...
graphics::plot(glmnet_res) 
```

The x-axis is the l1 norm of the coefficients (excluding intercept) and y-axis is the value of the coefficient. One line per coefficient, so we see the coefficients all start at 0 (on the left, when we penalize a LOT), and end up close to their linear regression counterpart (sometimes not exactly, due to the nature of the glmnet function) on the right, where almost no penalization is done. See `?glmnet:::plot.glmnet` for more documentation on how to change up this plot. Here is an example of x-axis is lambda.
```{r}
graphics::plot(glmnet_res, xvar = 'lambda')
```

But how do we choose which model to pick specifically? This is where `cv.glmnet` comes in, for cross-validation.

## Fitting Lasso (using cross-validation)
```{r}
set.seed(10)
cvglmnet_res <- glmnet::cv.glmnet(x = as.matrix(dat2[,-1]), y = dat2[,1], family = "gaussian",
                                  intercept = F)
class(cvglmnet_res) # it's a different class
names(cvglmnet_res) 
```
`lambda` contains the tuning parameter, `cvm` contains the mean estimated mse, `glmnet.fit` contains the fitted glmnet model, `lambda.min` and `lambda.1se` are two lambdas chosen by cross-validation.
```{r}
cvglmnet_res # it prints out something different from before
```
Remember, cross validation is random, so it's in your interest to set the seed beforehand. By default, 10 folds are used.

Let's try to plot `cvglmnet_res` now
```{r}
plot(cvglmnet_res) 
```
This is the cross validation plot. On the x-axis are different values of the penalty term (in this case, on the log scale), and the y-axis is the estimated MSE. the red dots denote mean estimated MSE, averaged over the 10 folds, and the error bars denote the std. deviation of the estimated MSE. 

These plots typically have two long vertical dotted lines. the one corresponding to the the smaller value of lambda represents `lambda.min`, the lambda that minimized the cross validation metric (i.e., minimum mean estimated mse). The other one represents `lambda.1se`, the lambda that is 1 standard error above lambda.min. Both are typically used in practice. `lambda.1se` gives a sparser model than lambda.min, at the cost of (potentially) worse predictive power.

we can make the fitted glmnet plot a bit more meaningful by marking `lambda.1se` and `lambda.min` explicitly, with a bit more code. you won't need to do anything like this for your homework
```{r}
plot(cvglmnet_res$glmnet.fit)
cv_idx <- which(names(cvglmnet_res) %in% c("lambda.min", "lambda.1se"))
for(i in cv_idx){
  lambda_idx <- which(cvglmnet_res$glmnet.fit$lambda == cvglmnet_res[i])
  l1_norm <- sum(abs(cvglmnet_res$glmnet.fit$beta[,lambda_idx]))
  lines(rep(l1_norm, 2), c(-1e3, 1e3), lwd = 2, lty = 2)
}

plot(cvglmnet_res$glmnet.fit, xvar = 'lambda')
cv_idx = cvglmnet_res$index
for(i in 1:2){
  log.lambda = log(cvglmnet_res$lambda[cv_idx[i]]);
  lines(rep(log.lambda, 2), c(-1e3, 1e3), lwd = 2, lty = 2)
}
```

Note: unlike `lm` or `glm`, there is no meaningful summary (so there is no meaningful way to compute standard errors for free). 
```{r}
summary(glmnet_res)
summary(cvglmnet_res)
```

## Exact Coefficents
Let's extract the coefficients from `cvglmnet_res`. there are many ways to do this. We will extract based on the `lambda.1se`.
### Method 1
What you would usually do, outside of this homework.
```{r}
coef_vec1 <- stats::coef(cvglmnet_res, s = "lambda.1se")
class(coef_vec1)
coef_vec1 # its in sparse matrix representation, so let's convert it to a more useable form
name_vec <- rownames(coef_vec1)
coef_vec1 <- as.numeric(coef_vec1)
names(coef_vec1) <- name_vec
coef_vec1
```
Observe that unlike glm and lm, the first term returned is ALWAYS the intercept, even though we had asked for no intercept. so let's remove it for this example.
```{r}
coef_vec1 <- coef_vec1[-1]
coef_vec1
```

### Method 2
For now, use the output_coefficients function provided for this homework.
```{r}
coef_vec2 <- output_coefficients(cvglmnet_res, dat2, 1)
coef_vec2 <- coef_vec2[-1]

sum(abs(coef_vec1 - coef_vec2)) <= 1e-6
```
### Method 3
We can directly extract the coefficients from the `cvglmnet_res`. This is somewhat unadvised unless you know what you're doing, but this is what you would need to do. If you (for some reason) wanted the coefficients that are not associated with `lambda.min` or `lambda.1se`.
```{r}
lambda_idx <- which(cvglmnet_res$glmnet.fit$lambda == cvglmnet_res$lambda.1se)
coef_vec3 <- cvglmnet_res$glmnet.fit$beta[,lambda_idx]

sum(abs(coef_vec1 - coef_vec3)) <= 1e-6
```

## Get Predictions
Let's now compute the predictions from `cvglmnet_res`. There are many ways to do this.
### Method 1
What you would usually do, outside of this homework.
```{r}
pred_vec1 <-  stats::predict(cvglmnet_res, newx = as.matrix(dat2[,-1]), s = "lambda.1se")
```
Note: this is VERY fincky. you have to convert newx into a matrix, and the matrix has to have exactly the same number of columns as the number of variables within `cvglmnet_res`.
```{r}
head(pred_vec1)
pred_vec1 <- as.numeric(pred_vec1)
```

### Method 2
For now, you can use the output_predictions function provided for this homework.
```{r}
pred_vec2 <- output_predictions(cvglmnet_res, dat2, 1)
head(pred_vec2)

sum(abs(pred_vec1 - pred_vec2)) <= 1e-6
```

### Method 3
Of course, if you're hardcore, you can compute these values yourself.
```{r}
pred_vec3 <- as.numeric(as.matrix(dat2[,-1]) %*% coef_vec1)
sum(abs(pred_vec1 - pred_vec3)) <= 1e-6
```

## Penalized Logistic Regression
This is more-or-less the same, so we briefly do it here. the main difference is the family. Let's start with fitting the model:
```{r}
idx <- which(colnames(dat) == "AnyCHD")
set.seed(10)
cvglmnet_res <- glmnet::cv.glmnet(x = as.matrix(dat[,-idx]), y = dat[,idx], family = "binomial",
                                  intercept = T)
```
Plotting
```{r}
## plotting:
plot(cvglmnet_res) # the y-axis is a different loss now, called binomial deviance (instead of MSE)
plot(cvglmnet_res$glmnet.fit) # similar to before
```
Get coefficients
```{r}
## get coefficients (one of 3 ways)
coef_vec <- output_coefficients(cvglmnet_res, dat, idx)
coef_vec
```
Get Predictions
```{r}
## get predictions (one of 3 ways)
pred_vec <- output_predictions(cvglmnet_res, dat, idx)
head(pred_vec)
```
The other ways to extract predictions are slightly more involved. See how output_predictions is implemented.
